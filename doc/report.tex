% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
%\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
%\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...


%%% The "real" document content comes below...

\title{Understanding 3D Scenes Using Visual Grammars}
\author{Abhishek Anand, Sherwin Li, Paul Heran Yang }


%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\begin{abstract}
In this project, we pose 3D scene understanding as a problem of parsing in a visual grammar. A parse tree gives us much more indepth understanding of a scene that just a labeling of points. It tells us how 3D primitives like planes, cylinders etc. combine to form parts, parts combine to form instances of objects and objects group consistently to form a scene. We can detect individual object instances(no need of non-maximal suppression) and also poses of objects.
\end{abstract}

\section{Introduction}
Most of the scene understanding problems are formulated as a pixel/superpixel labeling problem. A single pixel and it's neighbors don't have enough information to perform labeling. In some approaches, a precomputed set of patches or segments are required to be labeled. Very rarely, do these segments correspond one-to-one with instances of objects in a scene. Sometimes, an object might be split into multiple segments. Sometimes, different instances of possibly different objects are combined into a segment. Most of the approaches do oversegmentation(splitting an object into multiple segments is fine but merging is not). Even then, these algorithms cannot combine segments before attempting to label them and hence can't reliably reason about properties like size and overall shape of the object. 
Moreover, it has been shown that in humans, there is a lot of feedback going on from recognition areas to segmentation areas. This makes a lot of sense, because at many places, lower level features are not sufficient to do segmentation and seeing the bigger picture becomes indispensable for correct segmentation. Our visual grammar has rules for both merging segments and labeling them to parts. In this way, our algorithm will find jointly optimal segmentation and labeling(i.e it can model feedback from labeling to segmentation).
Finally, we show how our grammar can be made to reason about occlusions. It does so by introducing hallucinated segments in the most likely position of a missing part and the points in the hallucinated segment are indeed not visible from any camera position.

\section{Related Work}
\cite{girshick2011object} use grammars for detecting people in 2D images. It doesn't quite handle the problem of jointly interpreting a whole scene - where relationships between objects become important(like we find monitor on table). Also, the grammar model is used to only combine parts(which are detected by base classifiers) into objects. We capture all of these in a single coherent generative model.
\cite{zhu2011} uses a visual grammar model to combine small lines in images to big lines and boxes in 3D space. They jointly infer 3D geometry and detect some objects like walls and boxes. We want to detect a large range of semantic objects. Also, their model handles occlusion by having multiple rules - one for each configuration of missing parts. A rule with missing part might be invoked when the position for that part is not occluded.
%Our cost function has monotonocity properties which allows us to find us the optimal parsing in much less time complexity()
\section{Model}
We use a variant stochastic context free grammar where the terminal and non-terminal symbols have attributes attached to them and probability of a rule depends also on the attributes and of children. We can define our grammar as a 4 tuple (V,T,R,S). T is the set of terminals(atomic units) . For now, T={segment}. V is the set of non-terminals(classes which can be ) . V={plane, clylinder, tableTop, table, scene...}. Each symbol in V and T is asociated with a vector of features $x \in R^d$.
S is the set of production rules which combile a mixture of terminals and non-terminals to form a non-terminal. Here are few examples: \\
Plane $->$ segment\\
Plane $->$ Plane segment\\
TableTop $->$  Plane\\
Table  $->$ TableTop TableLeg\\
Table  $->$ TableTop TableLeg Drawer\\
\\
Each rule is associated with a probability function which takes the features of children and give a probability. Since we use a parametric model(GMM), only the parameters need to be stored(mixing probabilities, means and variance). These parameters would be learnt. For now, we assume that the grammar is in CNF(all rules have atmost 2 symbols in RHS). We can convert a grammar which is not in CNF to one which is in CNF by introducing auxilliary non-terminals.
In traditional CFGs, a rule can combine only a set of adjacent symbols. There , the input was a 1D string of terminals and a terminal was adjacent to the one before and the one next to it. In 3D , we have a general adjacency graph where 2 terminals(segments) are connected if the minimum distance between them is less that a {\it min\_dist} or there is an occluded region between the 2 segments.

\section{Learning}
We use a genetarive model for this task.
\begin{eqnarray}
P(x,t)&=&P(x|t)P(t) \\
&=& \prod_{n \in NT(t)}{P(x_{children(n)} |rule(n) )P(rule(n))}\\
P(x_{children(n)} |rule(n) ) &:& GMM(\theta _{rule(n)})\\
P(rule(n)) &:& Multinomial \\
\sum_{r \in rules:LHS(r)=A}{P(r))}=1
\end{eqnarray}
Here, t is a parse-tree. x contains the features of terminals. The feature of a non-terminal node is a fixed function of features of it's children. NT(t) gives the set of non-terminal nodes in the tree t.
The params for the prior probability of rules(multinomial distribution for P(rule(n))) can be simply estimated by fraction of counts. For example, we have only 2 rules for generating a table(the last 2 rules in the example). Suppose, we observe in the dataset that 70\% of the tables have drawers and 30\% dont. Then the prior probability of last rule is 0.7.
To compute the posterior probability of rules, we fit a GMM to data generated from parsings of objects in training set. To obviate the need for estimating the number of components, we use a dirichlet process gaussian mixture model with. 

\section{Inference}
Note that in the equation describing $P(x,t)$, t can be any subtree of any full parse-tree i.e root of t need not be S(the start symbol). During parsing, each non-terminal represents a tree(formed by it's children and their children). We can define cost of a non-terminal as:
\begin{eqnarray}
cost(t)&=&-log(P(x,t))
\end{eqnarray}
 Note that this cost function is superior i.e cost of a parent is no less than the cost of children. Hence, we can use dynamic programming to compute the least cost(most probable) parsing. The time complexity is linear in the size of the set U of possible NonTerminals(set of connected subsets of segments in the original adjacency graph). Depending on the adjacency graph, |U| can be polynomial in number of terminals(linear graph) or exponential(in dense graphs). Even if we have a 2D grid graph on n terminals, it can be shown that $|U|\ge 2^{\sqrt{n}}$ . So, dynamic programming is not feasible. We can hope to learn a probability function such that the probability of optimall parse-tree is higher that most non-terminals in U. If so, we can use (KLD) Knuth lightest derivation algorithm (an extension of dikshtra shortest path) which only generates the non-terminals which have lower cost(higher probability) than the optimal parse-tree. If the time, budget is even less, we can use MCMC to sample from the distribution of parse-trees as was done in \cite{zhu2011}. The KLD algorithm maintains a O, set of optimal symbols and a priotity queue P of canditate non-terminals.  Initially all the terminals(segments) are added to P.  At each step,the minimum cost member of P(say v) is extracted and transferrd to O. In this step, if new non-terminals can be generated by combining v with members in O, those are added to P. If v is a type of start symbol, the algorithm terminates successfuly. To handle occlusion, v can be also combined with a hallucinated symbol , it the optimal location of the hallucinated symbol, given the position of v and the rule lies in an occluded region


\section{Data}
Getting reasonable data for learning parameters of rules turned out to be the most difficult part. We tried to collect data from google sketchup which has 3D models for common house-hold objects

\section{Future Work}

{  
\bibliographystyle{apalike}
\bibliography{references}
}

\end{document}
